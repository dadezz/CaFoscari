{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stavamo parlndo degli alberi di decisione.\n",
    "# information gain\n",
    "l'errore di un dataset è misurato in termini di entropia delle etihette\n",
    "\n",
    "l'entropia è una misura di casualità\n",
    "minimo: 0. obbero tutti i record appartengono a una classe\n",
    "massimo: log m, dove m è il numero di classi.\n",
    "\n",
    "il $ D $ non è solo il dataset iniziale, ma si riferisce al dataset in qualsiasi momento della ricorsione.\n",
    "\n",
    "# gain ratio\n",
    "smorzo il gain ottenuto se faccio troppi figli, così da non incentivare la natività.\n",
    "for k-ary decision tree (instead of binary), information gain favor splits with several small partition, 'cause they are more likely to be pure.\n",
    "gain ratio normalizes the informtion gain. evita quindi di fare troppi split\n",
    "\n",
    "# Gini \n",
    "è un indice di distribuzione di un dataset. 1 meno la somma dei quadrati delle probabilità.\n",
    "vogliamo ridurre la dispersione per avere classi pure\n",
    "di default è la misura scelta per il decision tree classifier di sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boh manca un po' di roba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alberi di decisione / overfitting\n",
    "\n",
    "abbiamo visto che oltre a un certo numero di condizioni, l'errore nel test non diminuisce e, anzi, tende ad aumentare.\n",
    "MOdellando troppo il training, il modello cattura fenomeni esistenti nel training che però non hanno equivalenti nel test, quindi non esiste regola generalizzatrice, ma è solo una descrizione di alcuni casi specifici nel dataset.\n",
    "\n",
    "l'overfitting può essere dovuto a:\n",
    "1. low data quality:\n",
    "   1. presence of noise\n",
    "   2. lack of representative samples\n",
    "2. high model capacity (modello troppo complesso per descrivere i dati che abbiamo -> stiamo modellando gli errori)\n",
    "\n",
    "se un modello è troppo poco complesso, non risuciamo a modellare le regole, se invece è troppo complesso, ne modelliamo anche gli errori\n",
    "\n",
    "## esempio\n",
    "Considera il task di predirre se i mercati crescono o no nei prossimi 10 giorni. \n",
    "\n",
    "### approccio 1\n",
    "Assumi probabilità binaria di 0.5\n",
    "fai 10 random guesses:\n",
    "la prob di essere corretto 8 volte su 10 è circa 0.05 -> è estremamente improbabile essere un buon predittore\n",
    "\n",
    "### approccio diverso\n",
    "prrendi 50 predittori, ognuo fa 10 random guesses. qual è la probabilità che almeno uno faccia 8 predizioni corrette? 0.94\n",
    "\n",
    "se voglio predire un certo fenomeno e ho tanti predittori casuali (da soli sbagliati) è  comunque un problema percHé la probabilità che uno predica correttamente è molto alta, ma è solo un caso perché non conosce davvero il fenomeno -> molto pericoloso. è necessario riconoscere se la predizione è ragionata o giusta solo per caso.\n",
    "\n",
    "Per ogni feature cerchiamo di capire se dà una buona predizione. se ho tante feature, è molto probbile trovare uno split che funzioni bene, ma magari non c'entra nulla con il fenomeno.\n",
    "più sono i nodi degli alberi, più è probabile che gli split siano del tutto casuali -> vogliamo un modello il più semplice possibile\n",
    "\n",
    "# Come avere un modello semplice\n",
    "## validation set\n",
    "Non voglio guardare il modello migliore basandomi sul training per via dell'overfitting.\n",
    "NOn voglio guardare il modello migliore basandomi sul set perché son dati futuri\n",
    "\n",
    "-> \n",
    "\n",
    "divido ulteriormente il set del training per simulare dati mai visti prima. \n",
    "Misuro la performance sul validation.\n",
    "\n",
    "Il test è l'insieme di dati che uso per stimare l'accuatezza di un modello.\n",
    "il validation è l'insieme di dati che uso per scegliere i parametri del modello\n",
    "\n",
    "una vlta scelti i parametri, può essere un'idea allenare quel modello su tutto il dataset training. tanto ormai ho già scelto quello che voglio, più dati ho meglio è.\n",
    "\n",
    "quando i dati sono abbastanza, questo modello è semplice da usare e molto valido. può essere problematico su dataset piccolini\n",
    "\n",
    "##  pruning\n",
    "applicabile a qualunque modello, ma in particolare agli alberi di decisione.\n",
    "L'idea è che se ho due modelli con errore circa simile, prendo il modello più semplice.\n",
    "\n",
    "Pruning: mi dai un albero tot complesso e io ci taglio alcuni sottoalberi. Lo faccio stimando come cambiano gli errori: se tagliando l'errore non aumenta o quasi, è una buona scelta.\n",
    "\n",
    "pre pruning: a tempo di training (per decidere se mi fermo prima di fare troppe foglie)\n",
    "post pruning: mi dai il modello e te lo resistuisco semplificato.\n",
    "### errore di generalizzazione\n",
    "\n",
    "l'errore di uno specifico modello su un certo dataset è la media degli errori su ogni istanza.\n",
    "l'errore di gen è l'errore che farò su dati mai visti. $ Error_{gen} = Error_{D, M} + \\alpha * Complexity(M) $.\n",
    "come misuro la complessità e alfa?\n",
    "\n",
    "una buona misura della complessità è dividere il numero di foglie per le istanze: quanto il mio modello è piccolo rispetto alla dimensione dei dati.\n",
    "Un altra idea è sul numero di bit per esprimerlo (magari un albero ha tanti nodi, ma la struttura è sempre la stessa ed è facile comprimerlo. probabile che sia un albero buono)\n",
    "\n",
    "alfa è un peso che dò quando faccio pruning per capire se mi conviene o meno cambiare ilrapporto foglie/istanze. Al variare di alfa, faccio più o meno pruning e quindi devo capire anche l'alfa migliore\n",
    "\n",
    "## implementazione di sklearn\n",
    "sklearn implmeneta la complessità solo come numero di foglie. l'errore dell'albero è la somma dell'entropia delle foglie + alfa*numero di foglie.\n",
    "sta cosa vale per ogni sottoalbero\n",
    "\n",
    "l'idea è: vale la pena sostituirmi il sottoalbero con una foglia? (nel caso di foglia: errore + alfa*1).\n",
    "l'algoritmo fa pruning quando l'albero con la sola foglia dà lo stesso errore del sottoalbero.\n",
    "obv, più aumento alfa, più la'bero divernta costoso. l'alfa effettivo è quando i due errori si equivalgono. ogni nodo ha l suo alfa effettivo. dato alfa, prunare significa togliere i nodi con alfa effettivo sotto una soglia defnita a priori. la soglia si decide provandole tutte.\n",
    "\n",
    "il trade off tra complessità e accuratezza è un argomento su cui torneremo per tutti i modelli.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
