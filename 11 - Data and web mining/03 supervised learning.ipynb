{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dati\n",
    "ci occuperemo di dati tabellari:\n",
    "* ogni riga è un record (info che riguarda una certa istanza)\n",
    "* per ogni riga ho un certo numero di colonne che chiameremo features -> caratteristiche che definiscono un'istanza.\n",
    "\n",
    "tipicamente ogliamo fare un task di predizione.\n",
    "Per esempio: ogni colonna è un corso, e sulle righe i voti per studente. il task è predire se il tizio si laurea con la lode [chiamato variabile dipedente, label, etichetta e altri nomi]. \n",
    "Predico basandomi sulla base di uno storico dei dati.\n",
    "Possono esistere tantissimi modelli predittivi.\n",
    "Tipicamente si costruisce il modello guardando lo storico (stundenti passati), si cerca un pattern. Sto storico si chiama **training set**. Queste sono informazioni che si usano per allenare il modello. Una volta che ho il modello, posso applicarlo a nuove istanze.\n",
    "L'obbiettico è stduio il passato per poi fare predizioni su studenti mai visti prima.\n",
    "\n",
    "L'etichetta in questo caso è di \"classficazione\": si chiama così l'output binario.\n",
    "\n",
    "Per capire se il modello è buono o meno, uso un altro insieme di dati con le stesse features di prima, ma con istanze mai viste. Le diamo in pasto al modello e controlliamo se il risultato predetto è uguale a quello reale.\n",
    "\n",
    "La rappresentatività delle features è fondamentale per la riuscita del predittore (per esempio se baso lode/non lode sulle features sesso e anno di nascita, avrò predittori sbagliati perché le features non sono adatte a rappresentarmi il problema).\n",
    "\n",
    "Se l'etichetta è continua (per esmpio il voto invece della lode), cambia anche la valutazione del modello, perché sbaglia si/no è meno utile di sbaglia tanto/poco. \n",
    "Misuro lo scarto (dipende dalla feature \"quale\" scarto, se valore assoluto, sqm, scarto logaritmico etc). \n",
    "Lo scarto deve aiutarmi a distinguere un modello dall'altro e decidere quale è migliore.\n",
    "\n",
    "Il \"learning\"/\"training\" viene detto **supervised** perché l'etichetta è data, e si differenzia quindi dall' \"unsupervised learning\" AKA clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "è uno dei più semplici algoritmi di machine learning.\n",
    "input: dati tabellari\n",
    "## k-Nearest-Neighbor Classifier\n",
    "in pratica, confronta la tupla con quelle più simile nel dataset per fare le predizioni. si dice che impara per analogia.\n",
    "### Train e Test\n",
    "come visto prima, per verificare la validità di un modello, è necessario testarlo. \n",
    "Prendiamo quindi il dataset e lo splittiamo. Una parte delle righe disponibili viene usato per il training, il rimanente viene lasciato lì per l'esecuzione dei test.\n",
    "In genere si divide in 2/3 training e 1/3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(y, test_size=33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuratezza\n",
    "dicevamo che il caloclo dell'accuratezza è diverso tra i casi di label continue o discrete. In sto caso usiamo la *distanza* della predizione dal valore corretto.\n",
    "in `sklearn` abbiamola classe `KNeighborsClassifier`. È un modello classificatore cge sceglie un gruppo a seconda della frequenza di vicini che ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the classifier\n",
    "kNN = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Train the classifier\n",
    "kNN.fit(X_train,y_train)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = kNN.predict(X_test)\n",
    "\n",
    "# compute Accuracy\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print (f\"Accuracy {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione\n",
    "basandosi sulle distanze tra gli oggetti si è soggetti ad errori in quanto non si tiene conto del peso di ogni feature.\n",
    "Per esempio, i numeri possono essere più o meno alti a seconda dell'unità di misura. se misuro la distanza di età di due persone in secondi, mi vengono numeri enormi, e magari le distanze di tutte le altre feature diventano trascurabili a confronto. Le feature hanno \"peso\" confrontabile o sensato?\n",
    "Per risolvere questo si normalizza. tra 0 e 1 il range di ogni feature: `MinMaxScaler()`.\n",
    "Non solo, se so che tutti i dati hanno distribuzione gaussiana, posso normalizzarli con `StandardScaler()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset (dal file 03 DWM)\n",
    "\n",
    "Url: http://archive.ics.uci.edu/ml/datasets/Wine\n",
    "\n",
    "These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "\n",
    "\n",
    "The attributes are:\n",
    "\n",
    "1. Quality (1-3)\n",
    "2. Alcohol\n",
    "3. Malic acid\n",
    "4. Ash\n",
    "5. Alcalinity of ash\n",
    "6. Magnesium\n",
    "7. Total phenols\n",
    "8. Flavanoids\n",
    "9. Nonflavanoid phenols\n",
    "10. Proanthocyanins\n",
    "11. Color intensity\n",
    "12. Hue\n",
    "13. OD280/OD315 of diluted wines\n",
    "14. Proline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "df = pd.read_csv(data_url, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "da qui posso usare le funzioni viste lezione scorsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.describe().T\n",
    "df.info()\n",
    "\n",
    "# data preparation\n",
    "# convert to float to have precise and homogenous computation\n",
    "dataset = df.astype(float)\n",
    "print(\"dataset shape\", dataset.shape)\n",
    "\n",
    "# get features by removing class label\n",
    "# remove id\n",
    "X = dataset.loc[:,1:]\n",
    "print(\"X shape\", X.shape)\n",
    "\n",
    "# get class label\n",
    "y = dataset.loc[:,0]\n",
    "print(\"y shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print (X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # lo scaling si fa sul training set\n",
    "\n",
    "for k in range(1,11): # per trovare il miglior valore di k \n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    kNN.fit( scaler.transform(X_train), y_train ) # nel fare il\n",
    "        # modello, si appliica lo scaling trovato .transform sul training dataset\n",
    "    y_pred = kNN.predict( scaler.transform(X_test) ) # uso lo scaler trovato\n",
    "        # su X_train per fare la trasformazione del dataset di test\n",
    "\n",
    "    # compute Accuracy\n",
    "    acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    print (\"k: {:2d} | Accuracy {:.3f}\".format(k,acc) )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
